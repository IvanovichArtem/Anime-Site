import torch

class BaselineNN(torch.nn.Module):
    def __init__(self, feats_4_model, emb_shapes, drop=0.3):
        super().__init__()

        # Собираем размерность данных для линейного слоя
        c_tens_id_3d = "TENSOR_3D"
        eq_3D_num_feats = feats_4_model[c_tens_id_3d]["numerical"]

        c_tens_id_2d = "TENSOR_2D"
        c_num_feats_2d = feats_4_model[c_tens_id_2d]["numerical"]

        eq_1D_num_feats = feats_4_model["TENSOR_1D"]["numerical"]
        sum_req_num_feats = feats_4_model["headers"]

        # Размер входных данных для линейного слоя
        total_input_size = (
            len(eq_3D_num_feats) + 
            len(c_num_feats_2d) + 
            len(eq_1D_num_feats) + 
            len(sum_req_num_feats)
        )

        # Упрощённый линейный слой
        self.fc = torch.nn.Sequential(
            torch.nn.Dropout(drop),
            torch.nn.Linear(total_input_size, 1)
        )

    def forward(self, one_dim_data, tensor_2d, tensor_3d):
        # Вытаскиваем числовые данные из входов
        flatten_3d_num, _, _ = tensor_3d
        tensor_2d_num, _ = tensor_2d
        numerical_1d, _ = one_dim_data

        # Если 3D данные — это PackedSequence, распакуем их
        if isinstance(flatten_3d_num, torch.nn.utils.rnn.PackedSequence):
            flatten_3d_num, _ = torch.nn.utils.rnn.pad_packed_sequence(flatten_3d_num, batch_first=True)

        # Объединяем все данные в один вектор
        combined_data = torch.cat(
            (flatten_3d_num, tensor_2d_num, numerical_1d), 
            axis=-1
        )

        # Прогоняем через линейный слой и получаем логиты
        logits = self.fc(combined_data)

        return logits

    @staticmethod
    def preproc_input(ONE_DIM, TENSOR_2D, TENSOR_3D):
        return ONE_DIM, TENSOR_2D, TENSOR_3D
    
    def forward(self, **kwargs):
        tensor_1d, tensor_2d, tensor_3d = self.preproc_input(**kwargs)
        logits = self.forward(tensor_1d, tensor_2d, tensor_3d)
        return logits
