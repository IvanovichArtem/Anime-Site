{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import PackedSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeding_shapes = {}\n",
    "TENSOR_IDS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmLayer(): pass\n",
    "class PackedSequenceBatchNorm1d(): pass\n",
    "class PackedSequenceEmbedingLayer(): pass\n",
    "class EmbedingLayer(): pass\n",
    "def cat_packed_seq(): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(torch.Module):\n",
    "    def __init__(self, feats_4_model, emb_shapes, lstm_sizes, drop=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm_sizes = lstm_sizes\n",
    "\n",
    "        embeding_output_size = {}\n",
    "        for key in embeding_shapes.keys():\n",
    "            embeding_output_size[key] = sum(v[-1] for v in embeding_shapes[key])\n",
    "\n",
    "        #### 3D\n",
    "\n",
    "        c_tens_id = \"TENSOR_3D\"\n",
    "        eq_3D_num_feats = feats_4_model[c_tens_id][\"numerical\"]\n",
    "        c_input_size = embeding_output_size[c_tens_id] + len(eq_3D_num_feats)\n",
    "\n",
    "        self.eq_3d_lstm = LstmLayer(c_input_size, **lstm_sizes[TENSOR_IDS[\"EQ_3D\"]])\n",
    "        self.eq_3d_bn = PackedSequenceBatchNorm1d(len(eq_3D_num_feats))\n",
    "        self.eq_3d_emb = PackedSequenceEmbedingLayer(emb_shapes[c_tens_id])\n",
    "        ########\n",
    "\n",
    "        ##### 2D\n",
    "        c_tens_id = \"TENSOR_2D\"\n",
    "        c_num_feats = feats_4_model[c_tens_id][\"numerical\"]\n",
    "        c_input_size = (\n",
    "            embeding_output_size[c_tens_id]\n",
    "            + len(c_num_feats)\n",
    "            + lstm_sizes[TENSOR_IDS[\"EQ_3D\"][\"hidden_state\"]]\n",
    "        )\n",
    "        self.eq_2d_lstm = LstmLayer(c_input_size, **lstm_sizes[TENSOR_IDS[\"EQ_2D\"]])\n",
    "        self.eq_2d_bn = PackedSequenceBatchNorm1d(len(c_num_feats))\n",
    "        self.eq_2d_emb = PackedSequenceEmbedingLayer(emb_shapes[c_tens_id])\n",
    "        #####\n",
    "\n",
    "        #### 1D\n",
    "        eq_1D_num_feats = feats_4_model[\"TENSOR_1D\"][\"numerical\"]\n",
    "        sum_req_num_feats = feats_4_model[\"headers\"]\n",
    "\n",
    "        # MODIFICATION\n",
    "        concated_numerical_1d_data_size = len(eq_1D_num_feats) + len(sum_req_num_feats)\n",
    "        linear1_input_size = concated_numerical_1d_data_size + embeding_output_size['ONE_DIM']\n",
    "        linear1_input_size += lstm_sizes[TENSOR_IDS['EQ_2D']]['hidden_state']\n",
    "\n",
    "        self.fc_branc = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(drop),\n",
    "            torch.nn.Linear(linear1_input_size, 1)\n",
    "        )\n",
    "\n",
    "        self.bn1 = torch.nn.BatchNorm1d(\n",
    "            concated_numerical_1d_data_size\n",
    "        )\n",
    "        self.emb1 = EmbedingLayer(emb_shapes['ONE_DIM'])\n",
    "        ########\n",
    "\n",
    "    def forward_3d(self, tensor_3d):\n",
    "        flatten_3d_num, flatten_3d_emb, emb_3d_lens = tensor_3d\n",
    "        flatten_3d_num = self.eq_3d_bn(flatten_3d_num)\n",
    "\n",
    "        lstm_out = self.eq_3d_lstm(flatten_3d_num)\n",
    "\n",
    "        out = torch.split(lstm_out, emb_3d_lens)\n",
    "        out = torch.nn.utils.rnn.pack_sequence(out, enforce_sorted=False)\n",
    "        return out\n",
    "\n",
    "    def forward_2d(self, tensor_2d, tensor_3d_lstm_out):\n",
    "        tensor_2d_num, tensor_2d_emb = tensor_2d\n",
    "\n",
    "        num = self.eq_2d_bn(tensor_2d_num)\n",
    "\n",
    "        emb = self.eq_2d_emb(tensor_2d_emb)\n",
    "\n",
    "        data = cat_packed_seq([num, emb, tensor_3d_lstm_out])\n",
    "        return self.eq_2d_lstm(data)\n",
    "\n",
    "    def forward_1d(self, one_dim_data, eq_branch_out):\n",
    "        numerical_1d, embedings_1d = one_dim_data\n",
    "        numerical_1d = self.bn1(numerical_1d)\n",
    "        embedings_1d = self.emb1(embedings_1d)\n",
    "        fc = torch.cat(\n",
    "            (numerical_1d, embedings_1d, eq_branch_out),\n",
    "            axis = -1\n",
    "        )\n",
    "\n",
    "        logits = self.fc_branc(fc)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "    @staticmethod\n",
    "    def preproc_input(ONE_DIM, TENSOR_2D, TENSOR_3D):\n",
    "        return ONE_DIM, TENSOR_2D, TENSOR_3D\n",
    "    \n",
    "    def forward(self, **kwargs):\n",
    "        tensor_1d, tensor_2d, tensor_3d = self.preproc_input(**kwargs)\n",
    "\n",
    "        data_3d_out = self.forward_3d(tensor_3d)\n",
    "\n",
    "        data_2d_out = self.forward_2d(tensor_2d, data_3d_out)\n",
    "\n",
    "        logits = self.forward_1d(tensor_1d, data_2d_out)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# мое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NNWithoutLSTM(nn.Module):\n",
    "    def __init__(self, feats_4_model, emb_shapes, lstm_sizes, drop=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm_sizes = lstm_sizes\n",
    "\n",
    "        # Считаем размер выхода эмбеддингов\n",
    "        embeding_output_size = {}\n",
    "        for key in emb_shapes.keys():\n",
    "            embeding_output_size[key] = sum(v[-1] for v in emb_shapes[key])\n",
    "\n",
    "        #### 3D - Замена LSTM на полносвязный слой\n",
    "        c_tens_id = \"TENSOR_3D\"\n",
    "        eq_3D_num_feats = feats_4_model[c_tens_id][\"numerical\"]\n",
    "        c_input_size = embeding_output_size[c_tens_id] + len(eq_3D_num_feats)\n",
    "\n",
    "        self.eq_3d_fc = nn.Linear(c_input_size, lstm_sizes[\"EQ_3D\"][\"hidden_state\"])\n",
    "        self.eq_3d_bn = nn.BatchNorm1d(len(eq_3D_num_feats))\n",
    "        self.eq_3d_emb = nn.EmbeddingBag(embeding_output_size[c_tens_id], lstm_sizes[\"EQ_3D\"][\"hidden_state\"], mode='mean')\n",
    "        ########\n",
    "\n",
    "        ##### 2D - Замена LSTM на полносвязный слой\n",
    "        c_tens_id = \"TENSOR_2D\"\n",
    "        c_num_feats = feats_4_model[c_tens_id][\"numerical\"]\n",
    "        c_input_size = (\n",
    "            embeding_output_size[c_tens_id]\n",
    "            + len(c_num_feats)\n",
    "            + lstm_sizes[\"EQ_3D\"][\"hidden_state\"]  # Передаем скрытое состояние от 3D ветки\n",
    "        )\n",
    "\n",
    "        self.eq_2d_fc = nn.Linear(c_input_size, lstm_sizes[\"EQ_2D\"][\"hidden_state\"])\n",
    "        self.eq_2d_bn = nn.BatchNorm1d(len(c_num_feats))\n",
    "        self.eq_2d_emb = nn.EmbeddingBag(embeding_output_size[c_tens_id], lstm_sizes[\"EQ_2D\"][\"hidden_state\"], mode='mean')\n",
    "        #####\n",
    "\n",
    "        #### 1D - Полносвязная ветка\n",
    "        eq_1D_num_feats = feats_4_model[\"TENSOR_1D\"][\"numerical\"]\n",
    "        sum_req_num_feats = feats_4_model[\"headers\"]\n",
    "\n",
    "        # Расчет входных данных для 1D ветки\n",
    "        concated_numerical_1d_data_size = len(eq_1D_num_feats) + len(sum_req_num_feats)\n",
    "        linear1_input_size = concated_numerical_1d_data_size + embeding_output_size['ONE_DIM']\n",
    "        linear1_input_size += lstm_sizes[\"EQ_2D\"][\"hidden_state\"]\n",
    "\n",
    "        self.fc_branc = nn.Sequential(\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(linear1_input_size, 1)\n",
    "        )\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(concated_numerical_1d_data_size)\n",
    "        self.emb1 = nn.EmbeddingBag(embeding_output_size['ONE_DIM'], lstm_sizes['EQ_2D']['hidden_state'], mode='mean')\n",
    "        ########\n",
    "\n",
    "    def forward_3d(self, tensor_3d):\n",
    "        flatten_3d_num, flatten_3d_emb, emb_3d_lens = tensor_3d\n",
    "        flatten_3d_num = self.eq_3d_bn(flatten_3d_num)\n",
    "\n",
    "        # Полносвязный слой вместо LSTM\n",
    "        fc_out = F.relu(self.eq_3d_fc(flatten_3d_num))\n",
    "        return fc_out\n",
    "\n",
    "    def forward_2d(self, tensor_2d, tensor_3d_fc_out):\n",
    "        tensor_2d_num, tensor_2d_emb = tensor_2d\n",
    "\n",
    "        num = self.eq_2d_bn(tensor_2d_num)\n",
    "        emb = self.eq_2d_emb(tensor_2d_emb)\n",
    "\n",
    "        # Объединяем и передаем через полносвязный слой\n",
    "        data = torch.cat([num, emb, tensor_3d_fc_out], dim=-1)\n",
    "        fc_out = F.relu(self.eq_2d_fc(data))\n",
    "        return fc_out\n",
    "\n",
    "    def forward_1d(self, one_dim_data, eq_branch_out):\n",
    "        numerical_1d, embedings_1d = one_dim_data\n",
    "        numerical_1d = self.bn1(numerical_1d)\n",
    "        embedings_1d = self.emb1(embedings_1d)\n",
    "\n",
    "        # Объединяем и передаем через полносвязную ветку\n",
    "        fc = torch.cat((numerical_1d, embedings_1d, eq_branch_out), axis=-1)\n",
    "        logits = self.fc_branc(fc)\n",
    "        return logits\n",
    "\n",
    "    @staticmethod\n",
    "    def preproc_input(ONE_DIM, TENSOR_2D, TENSOR_3D):\n",
    "        return ONE_DIM, TENSOR_2D, TENSOR_3D\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        tensor_1d, tensor_2d, tensor_3d = self.preproc_input(**kwargs)\n",
    "\n",
    "        # Обрабатываем данные по 3D, 2D и 1D веткам\n",
    "        data_3d_out = self.forward_3d(tensor_3d)\n",
    "        data_2d_out = self.forward_2d(tensor_2d, data_3d_out)\n",
    "        logits = self.forward_1d(tensor_1d, data_2d_out)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NNWithConvLSTM(nn.Module):\n",
    "    def __init__(self, feats_4_model, emb_shapes, lstm_sizes, drop=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm_sizes = lstm_sizes\n",
    "\n",
    "        # Считаем размер выхода эмбеддингов\n",
    "        embeding_output_size = {}\n",
    "        for key in emb_shapes.keys():\n",
    "            embeding_output_size[key] = sum(v[-1] for v in emb_shapes[key])\n",
    "\n",
    "        #### 3D - Смешивание LSTM и Conv1d\n",
    "        c_tens_id = \"TENSOR_3D\"\n",
    "        eq_3D_num_feats = feats_4_model[c_tens_id][\"numerical\"]\n",
    "        c_input_size = embeding_output_size[c_tens_id] + len(eq_3D_num_feats)\n",
    "\n",
    "        self.eq_3d_lstm = LstmLayer(c_input_size, **lstm_sizes[\"EQ_3D\"])\n",
    "        self.eq_3d_bn = PackedSequenceBatchNorm1d(len(eq_3D_num_feats))\n",
    "        self.eq_3d_emb = PackedSequenceEmbedingLayer(emb_shapes[c_tens_id])\n",
    "\n",
    "        # Новый сверточный слой для обработки числовых данных\n",
    "        self.eq_3d_conv = nn.Conv1d(in_channels=len(eq_3D_num_feats), out_channels=32, kernel_size=3, padding=1)\n",
    "        self.eq_3d_conv_bn = nn.BatchNorm1d(32)\n",
    "        ########\n",
    "\n",
    "        ##### 2D - Смешивание LSTM и Conv1d\n",
    "        c_tens_id = \"TENSOR_2D\"\n",
    "        c_num_feats = feats_4_model[c_tens_id][\"numerical\"]\n",
    "        c_input_size = (\n",
    "            embeding_output_size[c_tens_id]\n",
    "            + len(c_num_feats)\n",
    "            + lstm_sizes[\"EQ_3D\"][\"hidden_state\"]  # Передаем скрытое состояние от 3D ветки\n",
    "        )\n",
    "\n",
    "        self.eq_2d_lstm = LstmLayer(c_input_size, **lstm_sizes[\"EQ_2D\"])\n",
    "        self.eq_2d_bn = PackedSequenceBatchNorm1d(len(c_num_feats))\n",
    "        self.eq_2d_emb = PackedSequenceEmbedingLayer(emb_shapes[c_tens_id])\n",
    "\n",
    "        # Новый сверточный слой для обработки числовых данных\n",
    "        self.eq_2d_conv = nn.Conv1d(in_channels=len(c_num_feats), out_channels=32, kernel_size=3, padding=1)\n",
    "        self.eq_2d_conv_bn = nn.BatchNorm1d(32)\n",
    "        #####\n",
    "\n",
    "        #### 1D\n",
    "        eq_1D_num_feats = feats_4_model[\"TENSOR_1D\"][\"numerical\"]\n",
    "        sum_req_num_feats = feats_4_model[\"headers\"]\n",
    "\n",
    "        # Расчет входных данных для 1D ветки\n",
    "        concated_numerical_1d_data_size = len(eq_1D_num_feats) + len(sum_req_num_feats)\n",
    "        linear1_input_size = concated_numerical_1d_data_size + embeding_output_size['ONE_DIM']\n",
    "        linear1_input_size += lstm_sizes[\"EQ_2D\"][\"hidden_state\"]\n",
    "\n",
    "        self.fc_branc = nn.Sequential(\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(linear1_input_size, 1)\n",
    "        )\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(concated_numerical_1d_data_size)\n",
    "        self.emb1 = EmbedingLayer(emb_shapes['ONE_DIM'])\n",
    "        ########\n",
    "\n",
    "    def forward_3d(self, tensor_3d):\n",
    "        flatten_3d_num, flatten_3d_emb, emb_3d_lens = tensor_3d\n",
    "\n",
    "        # Обрабатываем числовые данные через сверточный слой\n",
    "        flatten_3d_num = flatten_3d_num.unsqueeze(1)  # Добавляем размер для Conv1d\n",
    "        flatten_3d_num = F.relu(self.eq_3d_conv_bn(self.eq_3d_conv(flatten_3d_num)))\n",
    "        flatten_3d_num = flatten_3d_num.squeeze(1)  # Убираем добавленный размер\n",
    "        flatten_3d_num = self.eq_3d_bn(flatten_3d_num)\n",
    "\n",
    "        # Используем LSTM для обработки эмбеддингов\n",
    "        lstm_out = self.eq_3d_lstm(flatten_3d_num)\n",
    "        out = torch.split(lstm_out, emb_3d_lens)\n",
    "        out = torch.nn.utils.rnn.pack_sequence(out, enforce_sorted=False)\n",
    "        return out\n",
    "\n",
    "    def forward_2d(self, tensor_2d, tensor_3d_lstm_out):\n",
    "        tensor_2d_num, tensor_2d_emb = tensor_2d\n",
    "\n",
    "        # Обрабатываем числовые данные через сверточный слой\n",
    "        tensor_2d_num = tensor_2d_num.unsqueeze(1)  # Добавляем размер для Conv1d\n",
    "        tensor_2d_num = F.relu(self.eq_2d_conv_bn(self.eq_2d_conv(tensor_2d_num)))\n",
    "        tensor_2d_num = tensor_2d_num.squeeze(1)  # Убираем добавленный размер\n",
    "        num = self.eq_2d_bn(tensor_2d_num)\n",
    "\n",
    "        emb = self.eq_2d_emb(tensor_2d_emb)\n",
    "\n",
    "        # Объединяем данные и передаем через LSTM\n",
    "        data = cat_packed_seq([num, emb, tensor_3d_lstm_out])\n",
    "        return self.eq_2d_lstm(data)\n",
    "\n",
    "    def forward_1d(self, one_dim_data, eq_branch_out):\n",
    "        numerical_1d, embedings_1d = one_dim_data\n",
    "        numerical_1d = self.bn1(numerical_1d)\n",
    "        embedings_1d = self.emb1(embedings_1d)\n",
    "\n",
    "        # Объединяем данные и передаем в полносвязную ветку\n",
    "        fc = torch.cat(\n",
    "            (numerical_1d, embedings_1d, eq_branch_out),\n",
    "            axis=-1\n",
    "        )\n",
    "\n",
    "        logits = self.fc_branc(fc)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    @staticmethod\n",
    "    def preproc_input(ONE_DIM, TENSOR_2D, TENSOR_3D):\n",
    "        return ONE_DIM, TENSOR_2D, TENSOR_3D\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        tensor_1d, tensor_2d, tensor_3d = self.preproc_input(**kwargs)\n",
    "\n",
    "        # Обрабатываем данные по 3D, 2D и 1D веткам\n",
    "        data_3d_out = self.forward_3d(tensor_3d)\n",
    "        data_2d_out = self.forward_2d(tensor_2d, data_3d_out)\n",
    "        logits = self.forward_1d(tensor_1d, data_2d_out)\n",
    "\n",
    "        return logits\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
